{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyzMinaBF/CriminalLaw/blob/main/Crimina_Law_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaAxYMjVimK3"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wl87ZQBimK5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr3fk3XgimK6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from urllib.request import urlretrieve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urlretrieve(\"https://github.com/JyzMinaBF/CriminalLaw/raw/main/law1.pkl\", \"Criminal.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V7dHYTca8Rg",
        "outputId": "e2ce470e-46b1-44de-a8d0-5fadcc64b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Criminal.pkl', <http.client.HTTPMessage at 0x7f7739f5add0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqtI80C1imK7"
      },
      "outputs": [],
      "source": [
        "f = open('Criminal.pkl', 'rb')\n",
        "CriminalLaw = pickle.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc3LXWvTimK7"
      },
      "outputs": [],
      "source": [
        "# text_lines = [x.lstrip('\\u3000\\u3000') for x in lines]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9zI9XYBimK8"
      },
      "outputs": [],
      "source": [
        "# text = ''.join(text_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfBuaWDiimK8"
      },
      "outputs": [],
      "source": [
        "# text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejmUg0PPimK-"
      },
      "source": [
        "### 訓練 tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u19OZPdRimLA"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(char_level=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XETbH3mimLB"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([CriminalLaw])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgXQCcydimLB"
      },
      "source": [
        "試用一下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D49gCU0rimLC",
        "outputId": "2a5f414c-d583-4908-bed9-6889723cd44f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 29, 2, 13, 17]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([\"行為之處罰\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1VTnbSZimLC"
      },
      "source": [
        "變成文字。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yngYH0JnimLD",
        "outputId": "4ab01fe4-1ced-4af1-8b06-184467f9d0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9cdae16d804f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "''.join(tokenizer.sequences_to_texts([[0]])[0].split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUPKQYs2imLD"
      },
      "source": [
        "計算最大 id, 即不同的字的數目。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltkqu4sgimLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44be6aba-98c9-4a42-d55d-e372edaf97ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "972\n"
          ]
        }
      ],
      "source": [
        "max_id = len(tokenizer.word_index)\n",
        "print(max_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jTXQrCAimLE"
      },
      "outputs": [],
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([CriminalLaw]))-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEuPy1OdimLE"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjThwFmjimLF"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoArrPgmimLF"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a872VE17imLF"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:,:-1], windows[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKNHUY0ximLG"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0iabVInimLG"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfVHMHrYimLG"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVH3h4YWimLH"
      },
      "outputs": [],
      "source": [
        "model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=[None, max_id]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcsMeOzPimLH"
      },
      "outputs": [],
      "source": [
        "model.add(TimeDistributed(Dense(max_id, activation=\"softmax\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S68entpyimLH"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53hp8g_JimLH",
        "outputId": "e5b47cc3-f327-43fd-e61f-0ce52d7043fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "912/912 [==============================] - 751s 821ms/step - loss: 2.7001\n",
            "Epoch 2/10\n",
            "912/912 [==============================] - 757s 828ms/step - loss: 2.1619\n",
            "Epoch 3/10\n",
            "912/912 [==============================] - 757s 828ms/step - loss: 1.7318\n",
            "Epoch 4/10\n",
            "912/912 [==============================] - 744s 814ms/step - loss: 1.3783\n",
            "Epoch 5/10\n",
            "912/912 [==============================] - 748s 818ms/step - loss: 1.1341\n",
            "Epoch 6/10\n",
            "912/912 [==============================] - 745s 815ms/step - loss: 0.9570\n",
            "Epoch 7/10\n",
            "912/912 [==============================] - 759s 830ms/step - loss: 0.8183\n",
            "Epoch 8/10\n",
            "912/912 [==============================] - 751s 821ms/step - loss: 0.7082\n",
            "Epoch 9/10\n",
            "912/912 [==============================] - 753s 824ms/step - loss: 0.6211\n",
            "Epoch 10/10\n",
            "912/912 [==============================] - 746s 815ms/step - loss: 0.5522\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHHIuWQ1Aicq",
        "outputId": "18c645d0-f59c-49d6-b0f8-a17cac63851d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 128)         563712    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 972)        125388    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 689,100\n",
            "Trainable params: 689,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4LlZceFCxKt",
        "outputId": "7781ed97-4694-4b1f-eb7b-6d2ebc676621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znOmA_uDimLI"
      },
      "source": [
        "#### 把 model 存起來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERLFn6X7imLI"
      },
      "outputs": [],
      "source": [
        "model.save('CriminalLaw_rnn_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "#save the model architecture to JSON file\n",
        "with open('CriminalLaw_rnn.json', 'w') as json_file:\n",
        "    json_file.write(json_model)\n"
      ],
      "metadata": {
        "id": "4-5sp418Go8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('content/drive/My Drive/saved_model/CriminalLaw_rnn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mROtX8P_tjt",
        "outputId": "d46aa61a-b766-4bdc-a7d5-2c95c531acba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: content/drive/My Drive/saved_model/CriminalLaw_rnn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: content/drive/My Drive/saved_model/CriminalLaw_rnn/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f77358f2990> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7e46I7RimLI"
      },
      "source": [
        "#### 把 tokenizer 存起來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqtkTqx5imLI"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMM92AK1imLJ"
      },
      "outputs": [],
      "source": [
        "f = open('dream_tokenizer.pkl', 'wb')\n",
        "pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}